{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/User/Documents/le wagon project/coronanet_release_allvars.csv', encoding='mac_roman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "record_id\n",
      "policy_id\n",
      "entry_type\n",
      "correct_type\n",
      "update_type\n",
      "update_level\n",
      "description\n",
      "date_announced\n",
      "date_start\n",
      "date_end\n",
      "country\n",
      "ISO_A3\n",
      "ISO_A2\n",
      "init_country_level\n",
      "domestic_policy\n",
      "province\n",
      "city\n",
      "type\n",
      "type_sub_cat\n",
      "type_text\n",
      "institution_status\n",
      "target_country\n",
      "target_geog_level\n",
      "target_region\n",
      "target_province\n",
      "target_city\n",
      "target_other\n",
      "target_who_what\n",
      "target_direction\n",
      "travel_mechanism\n",
      "compliance\n",
      "enforcer\n",
      "index_high_est\n",
      "index_med_est\n",
      "index_low_est\n",
      "index_country_rank\n",
      "link\n",
      "date_updated\n",
      "recorded_date\n",
      "confirmed_cases\n",
      "deaths\n",
      "recovered\n",
      "new_tests\n",
      "total_tests\n",
      "total_tests_per_thousand\n",
      "tests_units\n",
      "Rank_FP\n",
      "Score_FP\n",
      "state_IDC\n",
      "muni_IDC\n",
      "dispersive_IDC\n",
      "constraining_IDC\n",
      "inclusive_IDC\n",
      "sfi_SFI\n",
      "ti_cpi_TI\n",
      "pop_WDI_PW\n",
      "gdp_WDI_PW\n",
      "gdppc_WDI_PW\n",
      "growth_WDI_PW\n",
      "lnpop_WDI_PW\n",
      "lngdp_WDI_PW\n",
      "lngdppc_WDI_PW\n",
      "disap_FA\n",
      "polpris_FA\n",
      "latentmean_FA\n",
      "transparencyindex_HR\n",
      "EmigrantStock_EMS\n",
      "v2x_polyarchy_VDEM\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keep the important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    " def tristans_columns(self):\n",
    "        df = self.copy()\n",
    "        df['date_announced'] = pd.to_datetime(df['date_announced'])\n",
    "        df['date_start'] = pd.to_datetime(df['date_start'])\n",
    "        df['date_end'] = pd.to_datetime(df['date_end'])\n",
    "        df['date_announced'].fillna(df['date_start'], inplace = True)\n",
    "        df['date_start'].clip(lower=df['date_announced'], inplace=True)\n",
    "        df_select = df[['policy_id', 'date_start', 'country',\n",
    "           'type', 'type_sub_cat','description', 'ISO_A3','compliance']]\n",
    "        df_select.drop_duplicates(subset=['policy_id'], inplace=True)\n",
    "        return df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "df= tristans_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_id\n",
      "date_start\n",
      "country\n",
      "type\n",
      "type_sub_cat\n",
      "description\n",
      "ISO_A3\n",
      "compliance\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_id           0\n",
       "date_start          0\n",
       "country             0\n",
       "type                0\n",
       "type_sub_cat    10257\n",
       "description         0\n",
       "ISO_A3            133\n",
       "compliance        125\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_id       0\n",
       "date_start      0\n",
       "country         0\n",
       "type            0\n",
       "type_sub_cat    0\n",
       "description     0\n",
       "ISO_A3          0\n",
       "compliance      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_id</th>\n",
       "      <th>date_start</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>type_sub_cat</th>\n",
       "      <th>description</th>\n",
       "      <th>ISO_A3</th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6721435</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Closure and Regulation of Schools</td>\n",
       "      <td>Preschool or childcare facilities (generally f...</td>\n",
       "      <td>\"All schools in Herat Ã± including temporarily ...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Mandatory (Unspecified/Implied)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6018486</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Closure and Regulation of Schools</td>\n",
       "      <td>Primary Schools (generally for children ages 1...</td>\n",
       "      <td>In parts of northern Samangan province, school...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Mandatory (Unspecified/Implied)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3558044</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Closure and Regulation of Schools</td>\n",
       "      <td>Preschool or childcare facilities (generally f...</td>\n",
       "      <td>\"On 14 March, the Government of Afghanistan an...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Mandatory (Unspecified/Implied)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2231982</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Closure and Regulation of Schools</td>\n",
       "      <td>Primary Schools (generally for children ages 1...</td>\n",
       "      <td>April 11, Afghanistan's \"President Ghani says ...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Mandatory (Unspecified/Implied)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1212064</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Closure and Regulation of Schools</td>\n",
       "      <td>Preschool or childcare facilities (generally f...</td>\n",
       "      <td>April 14 \"Afghanistan on Saturday announced th...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Mandatory (Unspecified/Implied)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45629</th>\n",
       "      <td>6143876</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Restriction and Regulation of Government Services</td>\n",
       "      <td>Election procedures (e.g. mail-in voting)</td>\n",
       "      <td>The Zimbabwean minister for health, who is als...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Mandatory (Unspecified/Implied)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45630</th>\n",
       "      <td>2531192</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Restrictions of Mass Gatherings</td>\n",
       "      <td>Prison population reduced (e.g. early release ...</td>\n",
       "      <td>A presidential amnesty was announced by the Zi...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Voluntary/Recommended but No Penalties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45631</th>\n",
       "      <td>2574281</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Restrictions of Mass Gatherings</td>\n",
       "      <td>Postponement of an annually recurring event</td>\n",
       "      <td>In Zimbabwe, the 40th independence anniversary...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Mandatory (Unspecified/Implied)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45632</th>\n",
       "      <td>6689905</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Restrictions of Mass Gatherings</td>\n",
       "      <td>Postponement of an annually recurring event</td>\n",
       "      <td>In Zimbabwe, the Zimbabwe International Trade ...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Mandatory (Unspecified/Implied)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45639</th>\n",
       "      <td>4781867</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Restrictions of Mass Gatherings</td>\n",
       "      <td>Attendance at religious services restricted (e...</td>\n",
       "      <td>The Zimbabwe minister of Information and publi...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Mandatory (Unspecified/Implied)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14555 rows Ã 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       policy_id date_start      country  \\\n",
       "4        6721435 2020-03-09  Afghanistan   \n",
       "7        6018486 2020-03-11  Afghanistan   \n",
       "10       3558044 2020-03-14  Afghanistan   \n",
       "18       2231982 2020-04-18  Afghanistan   \n",
       "21       1212064 2020-06-03  Afghanistan   \n",
       "...          ...        ...          ...   \n",
       "45629    6143876 2020-10-02     Zimbabwe   \n",
       "45630    2531192 2020-03-02     Zimbabwe   \n",
       "45631    2574281 2020-03-17     Zimbabwe   \n",
       "45632    6689905 2020-03-17     Zimbabwe   \n",
       "45639    4781867 2020-09-22     Zimbabwe   \n",
       "\n",
       "                                                    type  \\\n",
       "4                      Closure and Regulation of Schools   \n",
       "7                      Closure and Regulation of Schools   \n",
       "10                     Closure and Regulation of Schools   \n",
       "18                     Closure and Regulation of Schools   \n",
       "21                     Closure and Regulation of Schools   \n",
       "...                                                  ...   \n",
       "45629  Restriction and Regulation of Government Services   \n",
       "45630                    Restrictions of Mass Gatherings   \n",
       "45631                    Restrictions of Mass Gatherings   \n",
       "45632                    Restrictions of Mass Gatherings   \n",
       "45639                    Restrictions of Mass Gatherings   \n",
       "\n",
       "                                            type_sub_cat  \\\n",
       "4      Preschool or childcare facilities (generally f...   \n",
       "7      Primary Schools (generally for children ages 1...   \n",
       "10     Preschool or childcare facilities (generally f...   \n",
       "18     Primary Schools (generally for children ages 1...   \n",
       "21     Preschool or childcare facilities (generally f...   \n",
       "...                                                  ...   \n",
       "45629          Election procedures (e.g. mail-in voting)   \n",
       "45630  Prison population reduced (e.g. early release ...   \n",
       "45631        Postponement of an annually recurring event   \n",
       "45632        Postponement of an annually recurring event   \n",
       "45639  Attendance at religious services restricted (e...   \n",
       "\n",
       "                                             description ISO_A3  \\\n",
       "4      \"All schools in Herat Ã± including temporarily ...    AFG   \n",
       "7      In parts of northern Samangan province, school...    AFG   \n",
       "10     \"On 14 March, the Government of Afghanistan an...    AFG   \n",
       "18     April 11, Afghanistan's \"President Ghani says ...    AFG   \n",
       "21     April 14 \"Afghanistan on Saturday announced th...    AFG   \n",
       "...                                                  ...    ...   \n",
       "45629  The Zimbabwean minister for health, who is als...    ZWE   \n",
       "45630  A presidential amnesty was announced by the Zi...    ZWE   \n",
       "45631  In Zimbabwe, the 40th independence anniversary...    ZWE   \n",
       "45632  In Zimbabwe, the Zimbabwe International Trade ...    ZWE   \n",
       "45639  The Zimbabwe minister of Information and publi...    ZWE   \n",
       "\n",
       "                                   compliance  \n",
       "4             Mandatory (Unspecified/Implied)  \n",
       "7             Mandatory (Unspecified/Implied)  \n",
       "10            Mandatory (Unspecified/Implied)  \n",
       "18            Mandatory (Unspecified/Implied)  \n",
       "21            Mandatory (Unspecified/Implied)  \n",
       "...                                       ...  \n",
       "45629         Mandatory (Unspecified/Implied)  \n",
       "45630  Voluntary/Recommended but No Penalties  \n",
       "45631         Mandatory (Unspecified/Implied)  \n",
       "45632         Mandatory (Unspecified/Implied)  \n",
       "45639         Mandatory (Unspecified/Implied)  \n",
       "\n",
       "[14555 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    x = x.lower()\n",
    "    x = ''.join([letter for letter in x if not letter.isdigit()])\n",
    "    for p in string.punctuation:\n",
    "        x = x.replace(p, \" \")\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(x)\n",
    "    tokens = ' '.join([token for token in tokens if token not in stops])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_description'] = df.description.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        schools herat Ã± including temporarily learning...\n",
       "7        parts northern samangan province schools close...\n",
       "10       march government afghanistan announced schools...\n",
       "18       april afghanistan president ghani says schools...\n",
       "21       april afghanistan saturday announced closure e...\n",
       "                               ...                        \n",
       "45629    zimbabwean minister health also vice president...\n",
       "45630    presidential amnesty announced zimbabwe govern...\n",
       "45631    zimbabwe th independence anniversary celebrati...\n",
       "45632    zimbabwe zimbabwe international trade fair zit...\n",
       "45639    zimbabwe minister information publicity announ...\n",
       "Name: clean_description, Length: 14555, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_description'] = lemma(df['clean_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "df['clean_description'] = [stemmer.stem(word) for word in df['clean_description']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        schools herat Ã± including temporarily learning...\n",
       "7        parts northern samangan province schools close...\n",
       "10       march government afghanistan announced schools...\n",
       "18       april afghanistan president ghani says schools...\n",
       "21       april afghanistan saturday announced closure e...\n",
       "                               ...                        \n",
       "45629    zimbabwean minister health also vice president...\n",
       "45630    presidential amnesty announced zimbabwe govern...\n",
       "45631    zimbabwe th independence anniversary celebrati...\n",
       "45632    zimbabwe zimbabwe international trade fair zit...\n",
       "45639    zimbabwe minister information publicity announ...\n",
       "Name: clean_description, Length: 14555, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets encode my subcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_sub_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Preschool or childcare facilities (generally f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Primary Schools (generally for children ages 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Preschool or childcare facilities (generally f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Primary Schools (generally for children ages 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Preschool or childcare facilities (generally f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45629</th>\n",
       "      <td>Election procedures (e.g. mail-in voting)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45630</th>\n",
       "      <td>Prison population reduced (e.g. early release ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45631</th>\n",
       "      <td>Postponement of an annually recurring event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45632</th>\n",
       "      <td>Postponement of an annually recurring event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45639</th>\n",
       "      <td>Attendance at religious services restricted (e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14555 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            type_sub_cat\n",
       "4      Preschool or childcare facilities (generally f...\n",
       "7      Primary Schools (generally for children ages 1...\n",
       "10     Preschool or childcare facilities (generally f...\n",
       "18     Primary Schools (generally for children ages 1...\n",
       "21     Preschool or childcare facilities (generally f...\n",
       "...                                                  ...\n",
       "45629          Election procedures (e.g. mail-in voting)\n",
       "45630  Prison population reduced (e.g. early release ...\n",
       "45631        Postponement of an annually recurring event\n",
       "45632        Postponement of an annually recurring event\n",
       "45639  Attendance at religious services restricted (e...\n",
       "\n",
       "[14555 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['type_sub_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df['type_sub_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14,  85,  39,  62,  46,  77,  83,  47,   1,  63,  42,  48,  49,\n",
       "        35,  29,  21,  96,  26,  33,  11,  53,   3,   9, 108,  15,  66,\n",
       "        91,  45,  54,  84,  18,  31,  90,  89,  10,  28,  30,  51,  94,\n",
       "       102,  58, 104,  50,  52,  73,   6,  44,  86,   4,  97,  40,   2,\n",
       "        23,  57,  93,  60,  87, 101,  25,  68,  61,  20,  55,  22,  67,\n",
       "        17,  78,  75,  27,  13,  69,  65, 103,   5,  95,  64,  16,  56,\n",
       "        74,  24,  80,  43,  36,  72, 100,  98,  12,   7,  34, 111, 112,\n",
       "       109,  19,  71,  59,  79,   8,   0,  92, 110,  99,  41,  88,  82,\n",
       "        81, 105, 107,  37,  70,  76, 106,  38, 113,  32], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit_transform(list(pd.DataFrame(temp).reset_index()['index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['type_sub_cat'])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['encoded_sub-cat']= df['type_sub_cat'].map(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can run a Naive Bayes model and see its score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df = 0.05,max_features = 1000)\n",
    "X = vectorizer.fit_transform(df['clean_description']) \n",
    "y = df['encoded_sub-cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4492614221916867"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X,y)\n",
    "\n",
    "nb_model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets double check to see if the model can predict the right sub-cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.94573483e-04, 8.42802270e-03, 2.99009430e-03, ...,\n",
       "        8.46898764e-04, 9.88512874e-04, 5.53636928e-05],\n",
       "       [7.67306411e-04, 5.68897027e-02, 2.41427938e-03, ...,\n",
       "        8.41616745e-04, 8.53155435e-04, 4.98004106e-05],\n",
       "       [4.00406293e-04, 1.64920649e-02, 2.16785908e-03, ...,\n",
       "        6.35062782e-04, 7.93507870e-04, 3.53953772e-05],\n",
       "       ...,\n",
       "       [3.92220827e-04, 1.95670411e-02, 6.25330530e-03, ...,\n",
       "        6.51980239e-04, 7.78684936e-04, 4.23748579e-05],\n",
       "       [4.36394755e-04, 1.77963930e-02, 7.08033155e-03, ...,\n",
       "        7.86107728e-04, 9.29079831e-04, 4.78307787e-05],\n",
       "       [5.77005705e-04, 3.46218597e-02, 8.27846311e-03, ...,\n",
       "        9.04338908e-04, 8.14233062e-04, 5.46335257e-05]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I'll take the 46th line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22193185495054904, 0.14100540760585478, 0.04458132248781279]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(nb_model.predict_proba(X)[15], reverse = True)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.predict_proba(X)[15].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_id                                                      1939072\n",
       "date_start                                         2020-08-05 00:00:00\n",
       "country                                                    Afghanistan\n",
       "type                                 Closure and Regulation of Schools\n",
       "type_sub_cat         Higher education institutions (i.e. degree gra...\n",
       "description          Aug 4, Afghanistan \"has announced that all pri...\n",
       "ISO_A3                                                             AFG\n",
       "compliance                      Voluntary/Recommended but No Penalties\n",
       "clean_description    aug afghanistan announced private public unive...\n",
       "encoded_sub-cat                                                     28\n",
       "Name: 36, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22193185495054904"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.predict_proba(X)[15][63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Primary Schools (generally for children ages 10 and below)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_[63]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well... got it wrong this time, but he gets it right for the first one (try urself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I increase my score ? Need to do a nice grid search, maybe find a way to regroup some of the sub-cats, maybe only take the top 3 results, then REDO a naive Bayse pred from those => OVER THE WEEKEND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gonna try with a pipeline and Gridsearch now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =(df['clean_description']) \n",
    "y = df['encoded_sub-cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_id                     int64\n",
       "date_start           datetime64[ns]\n",
       "country                      object\n",
       "type                         object\n",
       "type_sub_cat                 object\n",
       "description                  object\n",
       "ISO_A3                       object\n",
       "compliance                   object\n",
       "clean_description            object\n",
       "encoded_sub-cat               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Set parameters to search\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1,1),(2,2)),\n",
    "    'tfidf__max_features': (1000,2000,3000),\n",
    "    'tfidf__max_df': (1,0.9,0.8,0.7),\n",
    "    'nb__alpha': (0,0.1)}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, \n",
    "                           verbose=1, scoring = \"accuracy\", \n",
    "                           refit=True, cv=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-b1068600e498>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-99e6964859a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After multiple gridsearches, I realised this wasnt working so I stuck to this one for now (I'm testing it on the last 155 subcats here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df = 0.05,max_features = 1000)\n",
    "X = vectorizer.fit_transform(df['clean_description'])[:14400]\n",
    "y = df['encoded_sub-cat'][:14400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44979166666666665"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X,y)\n",
    "\n",
    "nb_model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nb_model.predict(vectorizer.fit_transform(df['clean_description'])[14400:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "B =df['encoded_sub-cat'][14400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = A==B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    108\n",
       "True      47\n",
       "Name: encoded_sub-cat, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 59 true / 155 (keep that in mind for later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now im gonna try a SGDC model to see if it can give me a better pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDC = SGDClassifier()\n",
    "#No params for now\n",
    "# loss =âhingeâ, âlogâ, âmodified_huberâ, âsquared_hingeâ, âperceptronâ, or a regression loss: âsquared_lossâ, âhuberâ, âepsilon_insensitiveâ, or âsquared_epsilon_insensitiveâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['clean_description'])[:14400]\n",
    "y = df['encoded_sub-cat'][:14400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDC.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9179166666666667"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDC.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That seems waaaaay too high to be possible, i'll try it in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = SGDC.predict(vectorizer.fit_transform(df['clean_description'])[14400:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "B =df['encoded_sub-cat'][14400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = A==B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    94\n",
       "True     61\n",
       "Name: encoded_sub-cat, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41935483870967744"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65/155"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 65 true / 155 Already better !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now i need to play with the params to get the best pred, this might take some time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #4 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-1309adc38322>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'SGDC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;34m'nb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m ])\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, steps, memory)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;31m# validate names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: zip argument #4 must support iteration"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('SGDC', SGDClassifier()),\n",
    "    'nb', MultinomialNB()\n",
    "])\n",
    "\n",
    "# Set parameters to search\n",
    "parameters = {\n",
    "    'tfidf__max_features': (1000,2000, 5000,10000),\n",
    "    'tfidf__max_df': (1,0.8,0.6),\n",
    "    'SGDC__loss': ('log', 'modified_huber', 'squared_hinge', 'perceptron'),\n",
    "    'SGDC__alpha': (0.0001, 0.001, 0.01, 0.1, 1)}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, \n",
    "                           verbose=5600, scoring = \"accuracy\", \n",
    "                           refit=True, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =(df['clean_description']) \n",
    "y = df['encoded_sub-cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44706286499484715"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SGDC__alpha': 0.001,\n",
       " 'SGDC__loss': 'squared_hinge',\n",
       " 'tfidf__max_df': 0.2,\n",
       " 'tfidf__max_features': 5000,\n",
       " 'tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df= 0.2, max_features= 5000, ngram_range= (1, 1))\n",
    "X = vectorizer.fit_transform(df['clean_description'])[:14400]\n",
    "y = df['encoded_sub-cat'][:14400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='squared_hinge',\n",
       "       max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       tol=None, validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDC = SGDClassifier(alpha= 0.001, loss= 'squared_hinge')\n",
    "SGDC.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7127777777777777"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDC.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    92\n",
       "True     63\n",
       "Name: encoded_sub-cat, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = SGDC.predict(vectorizer.fit_transform(df['clean_description'])[14400:])\n",
    "B =df['encoded_sub-cat'][14400:]\n",
    "C = A==B\n",
    "C.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.64516129032258"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(63/155)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guess I cant get higher than this.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets try some new models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000, encoding=\"utf-8\",  \n",
    "      ngram_range = (1,3),  \n",
    "      token_pattern = \"[A-Za-z_][A-Za-z\\d_]*\")\n",
    "xgb_r = xg.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(df.clean_description).toarray()\n",
    "y = df[['encoded_sub-cat']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_r.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields clean_description",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-d1bc5cd67f99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    814\u001b[0m         train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n\u001b[0;32m    815\u001b[0m                                 \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m                                 missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         self._Booster = train(xgb_options, train_dmatrix,\n",
      "\u001b[1;32mc:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         data, feature_names, feature_types = _convert_dataframes(\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m         )\n\u001b[0;32m    522\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_convert_dataframes\u001b[1;34m(data, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    418\u001b[0m                                                             \u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                                                             \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m                                                             meta_type)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     data, feature_names, feature_types = _maybe_dt_data(data,\n",
      "\u001b[1;32mc:\\users\\user\\.venvs\\lewagon\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[1;34m(data, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    292\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[0;32m    293\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmeta\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields clean_description"
     ]
    }
   ],
   "source": [
    "xgb_r.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5560427968606463"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_r.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
